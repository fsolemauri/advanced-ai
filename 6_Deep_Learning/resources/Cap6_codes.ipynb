{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cap6_codes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M1.304 · Inteligencia Artificial Avanzada / M0.539 · Inteligencia Artificial</p>\n",
        "<p style=\"margin: 0; text-align:right;\">MU Ingeniería Informática / MU Ingeniería Computacional y Matemática</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>"
      ],
      "metadata": {
        "id": "1wKVB3o6tFrz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5epE8jp-bh-"
      },
      "source": [
        "## Código del capítulo 6: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyN_3L05-0Ge"
      },
      "source": [
        "Código 6.1: perceptrón multicapa como clasificador de dígitos de MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADHDlWSn-XaA",
        "outputId": "4d58bdf1-c971-4604-e039-b9d8b9a0d984"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# Configuracion general del programa\n",
        "batch_size  = 128\n",
        "num_classes = 10\n",
        "epochs      = 20\n",
        "\n",
        "\n",
        "# Organizar datos en entrenamiento y prueba\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train  = x_train.reshape(60000, 784)\n",
        "x_test   = x_test.reshape(10000, 784)\n",
        "\n",
        "# Los datos de entrada (pixeles) son enteros,\n",
        "# convertirlos a reales para trabajar con ellos\n",
        "x_train  = x_train.astype('float32')\n",
        "x_test   = x_test.astype('float32')\n",
        "\n",
        "# Normalizar los valores a 0..1\n",
        "x_train /= 255\n",
        "x_test  /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convertir cada numero de clase en un vector de 0s y 1s\n",
        "# para poderlo comparar con la salida softmax\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Definir el modelo de la red, con dos capas ocultas\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Compilar el modelo y entrenarlo\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "# Finalmente, evaluarlo con los datos de prueba\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 13s 26ms/step - loss: 0.4749 - accuracy: 0.8465 - val_loss: 0.1020 - val_accuracy: 0.9696\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1182 - accuracy: 0.9654 - val_loss: 0.0908 - val_accuracy: 0.9718\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0844 - accuracy: 0.9751 - val_loss: 0.0862 - val_accuracy: 0.9761\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0716 - accuracy: 0.9788 - val_loss: 0.0744 - val_accuracy: 0.9779\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.0801 - val_accuracy: 0.9810\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0548 - accuracy: 0.9844 - val_loss: 0.0857 - val_accuracy: 0.9803\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0581 - accuracy: 0.9848 - val_loss: 0.1022 - val_accuracy: 0.9769\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0525 - accuracy: 0.9868 - val_loss: 0.1083 - val_accuracy: 0.9820\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0514 - accuracy: 0.9875 - val_loss: 0.1145 - val_accuracy: 0.9820\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0480 - accuracy: 0.9888 - val_loss: 0.0974 - val_accuracy: 0.9824\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.1082 - val_accuracy: 0.9818\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0529 - accuracy: 0.9882 - val_loss: 0.1193 - val_accuracy: 0.9810\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0420 - accuracy: 0.9907 - val_loss: 0.1325 - val_accuracy: 0.9810\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0442 - accuracy: 0.9891 - val_loss: 0.1143 - val_accuracy: 0.9838\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0442 - accuracy: 0.9903 - val_loss: 0.1531 - val_accuracy: 0.9816\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1345 - val_accuracy: 0.9839\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0452 - accuracy: 0.9903 - val_loss: 0.1309 - val_accuracy: 0.9829\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0364 - accuracy: 0.9922 - val_loss: 0.1524 - val_accuracy: 0.9834\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0487 - accuracy: 0.9907 - val_loss: 0.1594 - val_accuracy: 0.9837\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.0433 - accuracy: 0.9913 - val_loss: 0.1321 - val_accuracy: 0.9839\n",
            "Test loss: 0.132053941488266\n",
            "Test accuracy: 0.9839000105857849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbVt2S_z-_1o"
      },
      "source": [
        "Código 6.2: clasificador de opiniones de películas mediante RNN con LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUgaroDT-3M7",
        "outputId": "837228b8-c60b-4fe6-f66b-0d5bfca8c51c"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "# Numero de palabras distintas usadas como maximo\n",
        "max_features = 20000\n",
        "# De cada opinion se toman las 80 primeras palabras\n",
        "maxlen = 80  \n",
        "# Y las opiniones se agrupan en lotes de 32\n",
        "batch_size = 32\n",
        "\n",
        "# Cargar los datos\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "# Empaquetar los ejemplos en matrices cuadradas (rellenar)\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "# Crear el modelo con tres capas\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar y entrenar\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluar con los datos de test\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Build model...\n",
            "Train...\n",
            "Epoch 1/15\n",
            "782/782 [==============================] - 221s 279ms/step - loss: 0.5176 - accuracy: 0.7231 - val_loss: 0.3698 - val_accuracy: 0.8368\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 219s 280ms/step - loss: 0.2443 - accuracy: 0.9057 - val_loss: 0.4064 - val_accuracy: 0.8354\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 218s 279ms/step - loss: 0.1449 - accuracy: 0.9474 - val_loss: 0.4597 - val_accuracy: 0.8304\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 218s 278ms/step - loss: 0.0918 - accuracy: 0.9689 - val_loss: 0.5842 - val_accuracy: 0.8102\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 218s 279ms/step - loss: 0.0641 - accuracy: 0.9791 - val_loss: 0.6424 - val_accuracy: 0.8180\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 217s 278ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.7403 - val_accuracy: 0.8222\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 222s 284ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.9045 - val_accuracy: 0.8142\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.8518 - val_accuracy: 0.8134\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.8796 - val_accuracy: 0.8140\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 219s 280ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 1.0354 - val_accuracy: 0.8126\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 218s 278ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.9270 - val_accuracy: 0.8107\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 217s 278ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 1.1386 - val_accuracy: 0.8128\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 217s 278ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.1678 - val_accuracy: 0.8116\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 218s 279ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.1453 - val_accuracy: 0.8099\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 218s 279ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 1.1148 - val_accuracy: 0.7976\n",
            "782/782 [==============================] - 22s 29ms/step - loss: 1.1148 - accuracy: 0.7976\n",
            "Test score: 1.1147913932800293\n",
            "Test accuracy: 0.7975999712944031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FyjG_B1_DcJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}